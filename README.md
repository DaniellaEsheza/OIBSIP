# Oasis Infobyte Internship Projects

This repository showcases the projects I completed during the Oasis Infobyte Internship. Each task allowed me to dive into data analysis and machine learning, addressing unique challenges while honing my technical skills. Below is an overview of the projects and their outcomes:

---

## **1. Exploratory Data Analysis (EDA) on Retail Sales Data**
#### PROJECT 1 PROPOSAL LEVEL 1
### Project Overview:

I analyzed two datasets to uncover meaningful insights:

- **Retail Sales Dataset:** Focused on regional and product-level sales performance.
  
Dataset: <a href="https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-align: center; text-decoration: none; border-radius: 5px;">Link</a>

- **Nutrition Facts for McDonald’s Menu:** Examined nutritional data to identify trends and anomalies.

Dataset:<a href="https://www.kaggle.com/datasets/mcdonalds/nutrition-facts" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-align: center; text-decoration: none; border-radius: 5px;">Link</a>

### Key Steps and Insights:

1. **Data Loading and Cleaning:** Handled missing values and ensured data consistency.
2. **Descriptive Statistics:** Computed key metrics like mean, median, and standard deviation.
3. **Time Series Analysis:** Identified seasonal sales patterns and peak periods.
4. **Customer and Product Analysis:** Explored customer behavior and product performance.
5. **Visualizations:** Utilized bar charts, line plots, and heatmaps to present findings.
6. **Recommendations:** Suggested strategies, including inventory optimization and promoting healthier menu items.

### Skills Gained:

- Proficiency in data cleaning and exploratory analysis.
- Ability to interpret statistical metrics and trends.
- Creating visualizations for effective storytelling.

---

## **2. Predicting House Prices with Linear Regression**
#### PROJECT 1 PROPOSAL LEVEL 2
### Project Overview:

Built a predictive model to estimate house prices based on features such as location, size, and amenities using linear regression.

Dataset:<a href="https://www.kaggle.com/code/ashydv/housing-price-prediction-linear-regression/input" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-align: center; text-decoration: none; border-radius: 5px;">Link</a>

### Key Steps and Insights:

1. **Data Exploration and Cleaning:** Addressed missing data and outliers to ensure reliability.
2. **Feature Selection:** Identified key factors like square footage and school proximity.
3. **Model Training:** Implemented a linear regression model using scikit-learn.
4. **Model Evaluation:** Evaluated performance using R-squared and Mean Squared Error (MSE).
5. **Visualization:** Created scatter plots to compare predicted vs. actual prices.

### Results:

- **Mean Squared Error:** 1221696706370.6606
- **R-squared:** 0.6703930880771853

### Skills Gained:

- Practical experience with linear regression.
- Evaluating and interpreting model performance.
- Visualizing feature-target relationships.

---

## **3. Wine Quality Prediction**
#### PROJECT 2 PROPOSAL LEVEL 2
### Project Overview:

Developed machine learning models to predict wine quality based on chemical properties like acidity, density, and alcohol content.

Dataset:<a href="https://www.kaggle.com/datasets/yasserh/wine-quality-dataset" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-align: center; text-decoration: none; border-radius: 5px;">Link</a>

### Key Steps and Insights:

1. **Data Preparation:** Normalized features and addressed imbalanced data.
2. **Model Training:** Compared three algorithms—Random Forest, Stochastic Gradient Descent (SGD), and Support Vector Classifier (SVC).
3. **Feature Analysis:** Identified top predictors, including alcohol content and volatile acidity.
4. **Visualization:** Used heatmaps and scatter plots to explore correlations.

### Results:

- **Random Forest Classifier Accuracy:** 89.08%
- **Stochastic Gradient Descent Classifier Accuracy:** 81.22%
- **Support Vector Classifier Accuracy:** 82.10%
- Random Forest emerged as the best-performing model.

### Skills Gained:

- Experience with classification algorithms.
- Engineering features for improved model performance.
- Visualizing complex datasets for insights.

---

## **4. Fraud Detection**
#### PROJECT 3 PROPOSAL LEVEL 2
### Project Overview:

Created a fraud detection system to identify suspicious transactions using machine learning and anomaly detection techniques.

Dataset: <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" target="_blank" style="display: inline-block; padding: 10px 20px; background-color: #4CAF50; color: white; text-align: center; text-decoration: none; border-radius: 5px;">Link</a>


### Key Steps and Insights:

1. **Anomaly Detection:** Detected deviations from normal transaction behavior.
2. **Model Training:** Tested algorithms like Logistic Regression, Decision Trees, and Neural Networks.
3. **Feature Engineering:** Designed new features to improve fraud detection accuracy.
4. **Real-Time Simulation:** Simulated a live environment for processing transactions.
5. **Evaluation:** Assessed models using metrics like precision, recall, and F1-score.

### Results:

- **Logistic Regression Accuracy:** 100%
  - Precision for fraud detection: 77%
  - Recall for fraud detection: 19%
- **Decision Tree Accuracy:** 100%
  - Precision for fraud detection: 44%
  - Recall for fraud detection: 45%
- **Neural Network Accuracy:** 100%
  - Precision for fraud detection: 89%
  - Recall for fraud detection: 38%
- **Real-Time Fraud Detection Simulation:**
  - Processed transaction flagged as legitimate: **[Amount: 5000 | Prediction: Legitimate]**

### Skills Gained:

- Building robust fraud detection pipelines.
- Evaluating models on imbalanced datasets.
- Implementing scalable real-time monitoring systems.
